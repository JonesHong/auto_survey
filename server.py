# server.py - ç²¾ç°¡ç‰ˆ (å«æ—¥èªŒ API)
import uvicorn
import os
import json
import csv
import sys
import subprocess
import asyncio
import time
from typing import List, Optional
from pathlib import Path

from fastapi import FastAPI, Request, BackgroundTasks, HTTPException, Depends, Query
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pretty_loguru import setup_fastapi_logging, configure_uvicorn
from pydantic import BaseModel, HttpUrl, EmailStr

from src.utils.logger_manager import app_logger
from src.config.manager import ConfigManager

# åœ¨ç¾æœ‰å°å…¥å¾Œæ·»åŠ 
from src.utils.graceful_shutdown import GracefulShutdown

# åˆå§‹åŒ–å„ªé›…é—œé–‰ç®¡ç†å™¨
graceful_shutdown = GracefulShutdown()
# åˆå§‹åŒ–
config = ConfigManager()

app = FastAPI(
    title="è‡ªå‹•åŒ–ä»»å‹™å•Ÿå‹•å™¨ API", description="é€é Web ä»‹é¢å•Ÿå‹•ç°½åˆ°èˆ‡æ¸¬é©—è‡ªå‹•åŒ–è…³æœ¬"
)
# éœæ…‹æª”æ¡ˆå’Œæ¨¡æ¿
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/auto_survey/static", StaticFiles(directory="static"), name="static_proxy")
templates = Jinja2Templates(directory="templates")


# ========== è³‡æ–™æ¨¡å‹ ==========
class AutomationRequest(BaseModel):
    attend_url: HttpUrl
    quiz_url: HttpUrl


class PersonalAutomationRequest(BaseModel):
    company_name: str
    name: str
    email: str
    attend_url: HttpUrl
    quiz_url: HttpUrl


class User(BaseModel):
    name: str
    email: EmailStr


class UserResponse(BaseModel):
    id: int
    name: str
    email: str


# ========== ç”¨æˆ¶ç®¡ç†å™¨ ==========
class UserManager:
    def __init__(self, csv_path: str = config.system.csv_path):
        self.csv_path = csv_path
        app_logger.info(f"ç”¨æˆ¶ç®¡ç†å™¨åˆå§‹åŒ–ï¼ŒCSV æª”æ¡ˆè·¯å¾‘: {self.csv_path}")
        self.ensure_csv_directory()
        self.users = self.load_users()
        self.next_id = max([user["id"] for user in self.users], default=0) + 1

    def ensure_csv_directory(self):
        os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)
        if not os.path.exists(self.csv_path):
            with open(self.csv_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow(["name", "email"])

    def load_users(self) -> List[dict]:
        users = []
        try:
            with open(self.csv_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for i, row in enumerate(reader, 1):
                    if row.get("name") and row.get("email"):
                        users.append(
                            {
                                "id": i,
                                "name": row["name"].strip(),
                                "email": row["email"].strip(),
                            }
                        )
        except FileNotFoundError:
            pass
        return users

    def save_users(self):
        with open(self.csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["name", "email"])
            for user in self.users:
                writer.writerow([user["name"], user["email"]])

    def get_all_users(self) -> List[dict]:
        return self.users.copy()

    def get_user_by_id(self, user_id: int) -> Optional[dict]:
        return next((user.copy() for user in self.users if user["id"] == user_id), None)

    def get_user_by_email(self, email: str) -> Optional[dict]:
        return next(
            (user.copy() for user in self.users if user["email"] == email), None
        )

    def add_user(self, name: str, email: str) -> dict:
        if self.get_user_by_email(email):
            raise ValueError("Email å·²å­˜åœ¨")
        new_user = {"id": self.next_id, "name": name, "email": email}
        self.users.append(new_user)
        self.next_id += 1
        self.save_users()
        return new_user.copy()

    def update_user(self, user_id: int, name: str, email: str) -> dict:
        user = self.get_user_by_id(user_id)
        if not user:
            raise ValueError("ç”¨æˆ¶ä¸å­˜åœ¨")
        existing_user = self.get_user_by_email(email)
        if existing_user and existing_user["id"] != user_id:
            raise ValueError("Email å·²è¢«å…¶ä»–ç”¨æˆ¶ä½¿ç”¨")

        for i, u in enumerate(self.users):
            if u["id"] == user_id:
                self.users[i].update({"name": name, "email": email})
                self.save_users()
                return self.users[i].copy()
        raise ValueError("ç”¨æˆ¶ä¸å­˜åœ¨")

    def delete_user(self, user_id: int) -> bool:
        for i, user in enumerate(self.users):
            if user["id"] == user_id:
                del self.users[i]
                self.save_users()
                return True
        return False


user_manager = UserManager()


# ========== æ—¥èªŒç®¡ç†å™¨ ==========
class LogManager:
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_file = self.log_dir / "[auto_survey]daily_latest.temp.log"

    def get_log_path(self) -> Path:
        """ç²å–æ—¥èªŒæ–‡ä»¶è·¯å¾‘"""
        return self.log_file

    def file_exists(self) -> bool:
        """æª¢æŸ¥æ—¥èªŒæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        return self.log_file.exists()

    def get_file_size(self) -> int:
        """ç²å–æ–‡ä»¶å¤§å°ï¼ˆå­—ç¯€ï¼‰"""
        return self.log_file.stat().st_size if self.file_exists() else 0

    def get_total_lines(self) -> int:
        """ç²å–ç¸½è¡Œæ•¸"""
        if not self.file_exists():
            return 0
        try:
            with open(self.log_file, "r", encoding="utf-8") as f:
                return sum(1 for _ in f)
        except Exception:
            return 0

    def read_lines(
        self, start_line: int = 0, limit: int = 100
    ) -> tuple[list[str], bool]:
        """
        è®€å–æŒ‡å®šç¯„åœçš„è¡Œ
        è¿”å›: (è¡Œåˆ—è¡¨, æ˜¯å¦é‚„æœ‰æ›´å¤šè¡Œ)
        """
        if not self.file_exists():
            return [], False

        lines = []
        has_more = False

        try:
            with open(self.log_file, "r", encoding="utf-8") as f:
                # è·³éå‰é¢çš„è¡Œ
                for _ in range(start_line):
                    if not f.readline():
                        break

                # è®€å–æŒ‡å®šæ•¸é‡çš„è¡Œ
                for i in range(limit):
                    line = f.readline()
                    if not line:
                        break
                    lines.append(line.rstrip("\n\r"))

                # æª¢æŸ¥æ˜¯å¦é‚„æœ‰æ›´å¤šè¡Œ
                has_more = bool(f.readline())

        except Exception as e:
            app_logger.error(f"è®€å–æ—¥èªŒæ–‡ä»¶éŒ¯èª¤: {e}")
            return [], False

        return lines, has_more

    def tail_lines(self, num_lines: int = 100) -> list[str]:
        """ç²å–æœ€å¾Œ N è¡Œ"""
        if not self.file_exists():
            return []

        try:
            with open(self.log_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
                return [line.rstrip("\n\r") for line in lines[-num_lines:]]
        except Exception as e:
            app_logger.error(f"è®€å–æ—¥èªŒå°¾éƒ¨éŒ¯èª¤: {e}")
            return []

    async def watch_file(self, start_pos: int = 0):
        """
        ç›£æ§æ–‡ä»¶è®ŠåŒ–ï¼Œyield æ–°å¢çš„è¡Œ
        ç”¨æ–¼ SSE å³æ™‚æ—¥èªŒè¿½è¹¤
        """
        if not self.file_exists():
            yield f"data: {json.dumps({'error': 'æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨'})}\n\n"
            return

        try:
            with open(self.log_file, "r", encoding="utf-8") as f:
                # ç§»å‹•åˆ°æŒ‡å®šä½ç½®
                f.seek(start_pos)

                while True:
                    line = f.readline()
                    if line:
                        # ç™¼é€æ–°è¡Œ
                        yield f"data: {json.dumps({'type': 'log', 'content': line.rstrip()})}\n\n"
                    else:
                        # æ²’æœ‰æ–°è¡Œï¼Œç™¼é€å¿ƒè·³
                        yield f"data: {json.dumps({'type': 'heartbeat', 'timestamp': time.time()})}\n\n"
                        await asyncio.sleep(1)  # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡

        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


log_manager = LogManager()


# ========== å·¥å…·å‡½æ•¸ ==========
def get_root_path_from_headers(request: Request) -> str:
    """æª¢æ¸¬ä»£ç†ç’°å¢ƒä¸¦è¿”å›æ ¹è·¯å¾‘"""
    host = request.headers.get("host", "")
    forwarded_for = request.headers.get("x-forwarded-for")
    return "/auto_survey" if (":7777" in host or forwarded_for) else ""


def verify_editor_access(
    editor: str = Query(None, description="ç·¨è¼¯è€…å¸³è™Ÿ"),
    password: str = Query(None, description="ç·¨è¼¯è€…å¯†ç¢¼"),
):
    """æ¬Šé™é©—è­‰"""
    if not editor or not password:
        raise HTTPException(
            status_code=403, detail="æ¬Šé™ä¸è¶³ï¼šéœ€è¦æä¾› editor å’Œ password åƒæ•¸"
        )

    if editor != config.system.editor_user or password != config.system.editor_password:
        raise HTTPException(
            status_code=403, detail="æ¬Šé™ä¸è¶³ï¼šeditor æˆ– password ä¸æ­£ç¢º"
        )


def run_task_in_subprocess(task_type: str, url: str, personal_info: dict = None):
    """åŸ·è¡Œå­é€²ç¨‹ä»»å‹™ - å¯¦æ™‚è¼¸å‡ºç‰ˆæœ¬"""
    command = [sys.executable, "playwright_worker.py", task_type, "--url", url]
    if personal_info:
        command.extend(["--personal_info", json.dumps(personal_info)])

    app_logger.info(f"ä¸»é€²ç¨‹ï¼šæº–å‚™åŸ·è¡Œå­é€²ç¨‹å‘½ä»¤: {' '.join(command)}")
    
    try:
        # æ–¹æ¡ˆ1ï¼šè®“å­é€²ç¨‹ç›´æ¥è¼¸å‡ºåˆ°æ§åˆ¶å°ï¼ˆå¯¦æ™‚é¡¯ç¤ºï¼‰
        result = subprocess.run(
            command, 
            check=False,
            text=True, 
            encoding="utf-8"
            # ä¸ä½¿ç”¨ capture_output=Trueï¼Œè®“è¼¸å‡ºç›´æ¥é¡¯ç¤º
        )
        
        if result.returncode != 0:
            app_logger.error(f"âŒ å­é€²ç¨‹ä»»å‹™ '{task_type}' åŸ·è¡Œå¤±æ•—ï¼Œè¿”å›ç¢¼: {result.returncode}")
        else:
            app_logger.info(f"âœ… å­é€²ç¨‹ä»»å‹™ '{task_type}' åŸ·è¡ŒæˆåŠŸã€‚")

    except FileNotFoundError:
        app_logger.error("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° 'playwright_worker.py'")
    except Exception as e:
        app_logger.error(f"âŒ åŸ·è¡Œå­é€²ç¨‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def run_tasks_in_background(attend_url: str, quiz_url: str):
    """æ‰¹æ¬¡è™•ç†èƒŒæ™¯ä»»å‹™"""
    app_logger.info("ğŸš€ æ‰¹æ¬¡èƒŒæ™¯ä»»å‹™å·²å•Ÿå‹•")
    try:
        if attend_url:
            run_task_in_subprocess("batch_attendance", attend_url)
        if quiz_url:
            run_task_in_subprocess("batch_quiz", quiz_url)
        app_logger.info("âœ… æ‰€æœ‰æ‰¹æ¬¡èƒŒæ™¯ä»»å‹™è§¸ç™¼å®Œç•¢")
    except Exception as e:
        app_logger.error(f"âŒ æ‰¹æ¬¡èƒŒæ™¯ä»»å‹™ç™¼ç”ŸéŒ¯èª¤: {e}")


def run_personal_tasks_in_background(
    company_name: str, name: str, email: str, attend_url: str, quiz_url: str
):
    """å€‹äººè™•ç†èƒŒæ™¯ä»»å‹™"""
    app_logger.info(f"ğŸ§‘â€ğŸ’¼ å€‹äººèƒŒæ™¯ä»»å‹™å·²å•Ÿå‹• - {name} ({email}) - {company_name}")
    personal_info = {"name": name, "email": email, "company_name": company_name}

    try:
        if attend_url:
            run_task_in_subprocess("personal_attendance", attend_url, personal_info)
        if quiz_url:
            run_task_in_subprocess("personal_quiz", quiz_url, personal_info)
        app_logger.info(f"âœ… {name} çš„å€‹äººä»»å‹™è§¸ç™¼å®Œç•¢")
    except Exception as e:
        app_logger.error(f"âŒ {name} çš„å€‹äººä»»å‹™ç™¼ç”ŸéŒ¯èª¤: {e}")


# ========== è·¯ç”±è¨»å†Šå™¨ ==========
def register_routes():
    """çµ±ä¸€è¨»å†Šæ‰€æœ‰è·¯ç”±ï¼Œé¿å…é‡è¤‡ç¨‹å¼ç¢¼"""

    # é é¢è·¯ç”±
    page_routes = [
        ("", "/", "index.html"),
        ("_proxy", "/auto_survey/", "index.html"),
        ("", "/csv", "csv_page.html"),
        ("_proxy", "/auto_survey/csv", "csv_page.html"),
        ("", "/personal", "personal_page.html"),
        ("_proxy", "/auto_survey/personal", "personal_page.html"),
        ("", "/log", "log.html"),
        ("_proxy", "/auto_survey/log", "log.html"),
    ]

    for suffix, path, template in page_routes:
        # åœ¨é é¢è·¯ç”±çš„è™•ç†å‡½æ•¸ä¸­ä¿®æ”¹
        @app.get(path, response_class=HTMLResponse)
        async def page_handler(request: Request, admin_show: bool = False, template_name=template):
            root_path = get_root_path_from_headers(request)
            context = {"request": request, "root_path": root_path}
            if template_name == "csv_page.html":
                context["admin_mode"] = admin_show
            
            response = templates.TemplateResponse(template_name, context)
            
            # å¦‚æœæ˜¯ log é é¢ï¼Œæ·»åŠ å…è¨± iframe çš„é ­
            if template_name == "log.html":
                response.headers["X-Frame-Options"] = "SAMEORIGIN"
                response.headers["Content-Security-Policy"] = "frame-ancestors 'self'"
            
            return response

    # æ—¥èªŒ API è·¯ç”±
    @app.get("/api/log/info")
    async def get_log_info():
        """ç²å–æ—¥èªŒæ–‡ä»¶åŸºæœ¬è³‡è¨Š"""
        return {
            "file_exists": log_manager.file_exists(),
            "file_size": log_manager.get_file_size(),
            "total_lines": log_manager.get_total_lines(),
            "file_path": str(log_manager.get_log_path()),
        }

    @app.get("/api/log")
    async def get_log_content(
        page: int = Query(1, ge=1, description="é ç¢¼ï¼Œå¾1é–‹å§‹"),
        limit: int = Query(100, ge=1, le=1000, description="æ¯é è¡Œæ•¸ï¼Œæœ€å¤§1000"),
        tail: Optional[int] = Query(None, ge=1, le=5000, description="ç²å–æœ€å¾ŒNè¡Œ"),
    ):
        """
        åˆ†é ç²å–æ—¥èªŒå…§å®¹
        - page: é ç¢¼
        - limit: æ¯é è¡Œæ•¸
        - tail: å¦‚æœæŒ‡å®šï¼Œå‰‡å¿½ç•¥åˆ†é ï¼Œç›´æ¥è¿”å›æœ€å¾ŒNè¡Œ
        """
        if not log_manager.file_exists():
            raise HTTPException(status_code=404, detail="æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨")

        if tail:
            # è¿”å›æœ€å¾Œ N è¡Œ
            lines = log_manager.tail_lines(tail)
            return {
                "mode": "tail",
                "lines": lines,
                "count": len(lines),
                "total_lines": log_manager.get_total_lines(),
            }

        # åˆ†é æ¨¡å¼
        start_line = (page - 1) * limit
        lines, has_more = log_manager.read_lines(start_line, limit)

        return {
            "mode": "paginated",
            "page": page,
            "limit": limit,
            "lines": lines,
            "count": len(lines),
            "has_more": has_more,
            "total_lines": log_manager.get_total_lines(),
        }

    @app.get("/api/log/stream")
    async def stream_log_content(
        start_line: int = Query(0, ge=0, description="é–‹å§‹è¡Œæ•¸"),
        chunk_size: int = Query(50, ge=1, le=200, description="æ¯æ¬¡å‚³é€è¡Œæ•¸"),
    ):
        """
        ä¸²æµæ–¹å¼å‚³é€æ—¥èªŒå…§å®¹ï¼ˆéå³æ™‚ï¼‰
        é©åˆä¸€æ¬¡æ€§è®€å–å¤§å‹æ—¥èªŒæ–‡ä»¶
        """
        if not log_manager.file_exists():
            raise HTTPException(status_code=404, detail="æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨")

        async def generate_log_chunks():
            current_line = start_line

            while True:
                lines, has_more = log_manager.read_lines(current_line, chunk_size)

                if not lines:
                    break

                chunk_data = {
                    "lines": lines,
                    "start_line": current_line,
                    "count": len(lines),
                    "has_more": has_more,
                }

                yield f"data: {json.dumps(chunk_data)}\n\n"

                if not has_more:
                    break

                current_line += len(lines)
                await asyncio.sleep(0.1)  # é¿å…é˜»å¡

            # ç™¼é€çµæŸä¿¡è™Ÿ
            yield f"data: {json.dumps({'type': 'end'})}\n\n"

        return StreamingResponse(
            generate_log_chunks(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"},
        )

    @app.get("/api/log/watch")
    async def watch_log_realtime(
        tail: int = Query(10, ge=0, le=100, description="åˆå§‹é¡¯ç¤ºæœ€å¾ŒNè¡Œ")
    ):
        """
        SSE å³æ™‚ç›£æ§æ—¥èªŒ
        æœƒå…ˆç™¼é€æœ€å¾Œ N è¡Œï¼Œç„¶å¾Œå³æ™‚æ¨é€æ–°å¢çš„æ—¥èªŒ
        """
        if not log_manager.file_exists():
            raise HTTPException(status_code=404, detail="æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨")

        async def generate_realtime_logs():
            # å…ˆç™¼é€ SSE æ¨™é ­
            yield f"data: {json.dumps({'type': 'connected', 'message': 'å·²é€£æ¥åˆ°æ—¥èªŒç›£æ§'})}\n\n"

            # ç™¼é€æœ€å¾Œ N è¡Œä½œç‚ºæ­·å²è¨˜éŒ„
            if tail > 0:
                history_lines = log_manager.tail_lines(tail)
                for line in history_lines:
                    yield f"data: {json.dumps({'type': 'history', 'content': line})}\n\n"

            # ç²å–ç•¶å‰æ–‡ä»¶å¤§å°ä½œç‚ºèµ·å§‹ä½ç½®
            start_pos = log_manager.get_file_size()

            # é–‹å§‹å³æ™‚ç›£æ§
            async for event in log_manager.watch_file(start_pos):
                yield event

        return StreamingResponse(
            generate_realtime_logs(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",  # å° Nginx ä»£ç†æœ‰ç”¨
            },
        )

    # ç‚ºä»£ç†è¨ªå•æ·»åŠ æ—¥èªŒ API
    @app.get("/auto_survey/api/log/info")
    async def get_log_info_proxy():
        return await get_log_info()

    @app.get("/auto_survey/api/log")
    async def get_log_content_proxy(
        page: int = Query(1, ge=1),
        limit: int = Query(100, ge=1, le=1000),
        tail: Optional[int] = Query(None, ge=1, le=5000),
    ):
        return await get_log_content(page, limit, tail)

    @app.get("/auto_survey/api/log/stream")
    async def stream_log_content_proxy(
        start_line: int = Query(0, ge=0), chunk_size: int = Query(50, ge=1, le=200)
    ):
        return await stream_log_content(start_line, chunk_size)

    @app.get("/auto_survey/api/log/watch")
    async def watch_log_realtime_proxy(tail: int = Query(10, ge=0, le=100)):
        return await watch_log_realtime(tail)

    # API è·¯ç”±
    api_prefixes = ["", "/auto_survey"]

    for prefix in api_prefixes:
        # ç”¨æˆ¶ CRUD
        @app.get(f"{prefix}/api/users", response_model=List[UserResponse])
        async def get_users():
            return user_manager.get_all_users()

        @app.post(f"{prefix}/api/users", response_model=UserResponse)
        async def create_user(user: User, _=Depends(verify_editor_access)):
            try:
                return user_manager.add_user(user.name, user.email)
            except ValueError as e:
                raise HTTPException(status_code=400, detail=str(e))

        @app.get(f"{prefix}/api/users/{{user_id}}", response_model=UserResponse)
        async def get_user(user_id: int):
            user = user_manager.get_user_by_id(user_id)
            if not user:
                raise HTTPException(status_code=404, detail="ç”¨æˆ¶ä¸å­˜åœ¨")
            return user

        @app.put(f"{prefix}/api/users/{{user_id}}", response_model=UserResponse)
        async def update_user(
            user_id: int, user: User, _=Depends(verify_editor_access)
        ):
            try:
                return user_manager.update_user(user_id, user.name, user.email)
            except ValueError as e:
                raise HTTPException(status_code=400, detail=str(e))

        @app.delete(f"{prefix}/api/users/{{user_id}}")
        async def delete_user(user_id: int, _=Depends(verify_editor_access)):
            if not user_manager.delete_user(user_id):
                raise HTTPException(status_code=404, detail="ç”¨æˆ¶ä¸å­˜åœ¨")
            return {"message": "ç”¨æˆ¶å·²åˆªé™¤"}

        # è‡ªå‹•åŒ–ä»»å‹™
        @app.post(f"{prefix}/run-automation")
        async def start_automation(
            payload: AutomationRequest, background_tasks: BackgroundTasks
        ):
            attend_url, quiz_url = str(payload.attend_url), str(payload.quiz_url)
            if not attend_url or not quiz_url:
                raise HTTPException(
                    status_code=400, detail="ç°½åˆ°èˆ‡æ¸¬é©— URL çš†ç‚ºå¿…å¡«é …ã€‚"
                )

            users = user_manager.get_all_users()
            if not users:
                raise HTTPException(
                    status_code=400, detail="è«‹å…ˆæ–°å¢ç”¨æˆ¶è³‡æ–™æ‰èƒ½å•Ÿå‹•æ‰¹æ¬¡ä»»å‹™ã€‚"
                )

            app_logger.info(
                f"æ”¶åˆ°æ‰¹æ¬¡è«‹æ±‚: ç°½åˆ° URL='{attend_url}', æ¸¬é©— URL='{quiz_url}', ç”¨æˆ¶æ•¸={len(users)}"
            )
            background_tasks.add_task(run_tasks_in_background, attend_url, quiz_url)

            return {
                "status": "success",
                "message": f"æ‰¹æ¬¡è«‹æ±‚å·²æ¥æ”¶ (å…± {len(users)} ä½ç”¨æˆ¶)ï¼Œè‡ªå‹•åŒ–ä»»å‹™å·²åœ¨èƒŒæ™¯å­é€²ç¨‹é–‹å§‹åŸ·è¡Œã€‚",
            }

        @app.post(f"{prefix}/run-personal-automation")
        async def start_personal_automation(
            payload: PersonalAutomationRequest, background_tasks: BackgroundTasks
        ):
            data = [
                payload.company_name.strip(),
                payload.name.strip(),
                payload.email.strip(),
                str(payload.attend_url),
                str(payload.quiz_url),
            ]

            if not all(data):
                raise HTTPException(status_code=400, detail="æ‰€æœ‰æ¬„ä½çš†ç‚ºå¿…å¡«é …ã€‚")

            company_name, name, email, attend_url, quiz_url = data
            app_logger.info(f"æ”¶åˆ°å€‹äººè«‹æ±‚: {name} ({email}) - {company_name}")

            background_tasks.add_task(
                run_personal_tasks_in_background,
                company_name,
                name,
                email,
                attend_url,
                quiz_url,
            )

            return {
                "status": "success",
                "message": f"å€‹äººè«‹æ±‚å·²æ¥æ”¶ï¼Œ{name} çš„è‡ªå‹•åŒ–ä»»å‹™å·²åœ¨èƒŒæ™¯å­é€²ç¨‹é–‹å§‹åŸ·è¡Œã€‚",
            }


# è¨»å†Šæ‰€æœ‰è·¯ç”±
register_routes()

# ========== å•Ÿå‹• ==========
if __name__ == "__main__":
    HOST, PORT = "0.0.0.0", 51000
    
    info_messages = [
        f"ğŸš€ å•Ÿå‹•ä¼ºæœå™¨æ–¼ http://{HOST}:{PORT}",
        "ğŸŒ æœ¬åœ°è¨ªå•: http://localhost:51000 æˆ– http://127.0.0.1:51000",
        "ğŸŒ å¤–éƒ¨è¨ªå•: http://114.33.18.107:7777/auto_survey/",
        "ğŸ  é¦–é : / (æœ¬åœ°) æˆ– /auto_survey/ (å¤–éƒ¨)",
        "ğŸ“‹ æ‰¹æ¬¡è™•ç†: /csv (æœ¬åœ°) æˆ– /auto_survey/csv (å¤–éƒ¨)",
        "ğŸ‘¤ å€‹äººå¡«è¡¨: /personal (æœ¬åœ°) æˆ– /auto_survey/personal (å¤–éƒ¨)",
        "ğŸ”— API ç«¯é»: /api/* (æœ¬åœ°) æˆ– /auto_survey/api/* (å¤–éƒ¨)",
        "ğŸ“ ç”¨æˆ¶è³‡æ–™å„²å­˜æ–¼: data/users.csv",
        "ğŸ“ éœæ…‹æª”æ¡ˆ: /static (æœ¬åœ°) æˆ– /auto_survey/static (å¤–éƒ¨)",
    ]
    
    for msg in info_messages:
        app_logger.info(msg)
    
    uv_config = uvicorn.Config(
            app, 
            host=HOST, 
            port=PORT,
            log_level="warning",
            access_log=False
    )
    server = uvicorn.Server(uv_config)
    
    configure_uvicorn(logger_instance=app_logger)
    setup_fastapi_logging(
        app, logger_instance=app_logger,
        middleware=False,  # <---- é€™è£¡é—œæ‰
        log_request_body=False,
        log_response_body=False
    )
    try:
        server.run()
    except (KeyboardInterrupt, asyncio.exceptions.CancelledError, SystemExit):
        app_logger.info("âš¡ æ”¶åˆ° Ctrl+C ä¸­æ–·ä¿¡è™Ÿ")
    except Exception as e:
        app_logger.error(f"âŒ ä¼ºæœå™¨éŒ¯èª¤: {e}")
    finally:
        # æ‰‹å‹•è§¸ç™¼æ¸…ç†ï¼ˆå› ç‚ºä¿¡è™Ÿè™•ç†å™¨å·²ç¶“åŸ·è¡Œéäº†ï¼‰
        if not graceful_shutdown.is_shutdown:
            graceful_shutdown.cleanup()
        app_logger.info("âœ… ä¼ºæœå™¨å·²åœæ­¢")