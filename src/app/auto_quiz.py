# auto_quiz.py

"""
è‡ªå‹•å•å·å¡«å¯«ç¨‹å¼ - é‡æ§‹ç‰ˆ
ä½¿ç”¨å…±ç”¨æ¨¡çµ„ï¼Œå°ˆæ³¨æ–¼å•å·ç‰¹æœ‰çš„ GPT åˆ†æåŠŸèƒ½
"""
import openai
import json
import re
import asyncio
from datetime import datetime
from utils.survey_utils import CacheManager, batch_process_forms, batch_process_forms_from_manager
from playwright.async_api import async_playwright

from src.config.manager import ConfigManager
from src.utils.logger_manager import app_logger
config = ConfigManager()

# é…ç½® (å¾è¨­å®šæª”è®€å–ï¼Œä¸å†éœ€è¦ç¡¬ç·¨ç¢¼ URL)
OPENAI_API_KEY = config.system.openai_api_key
CSV_PATH = config.system.csv_path
openai_model = config.system.openai_model
company_name = config.system.company_name

# ========== å•å·ç‰¹æœ‰åŠŸèƒ½ ==========
def generate_option_letters(count):
    """å‹•æ…‹ç”Ÿæˆé¸é …å­—æ¯ A, B, C, D, E, F, G, H..."""
    return [chr(ord('A') + i) for i in range(count)]

async def should_skip_question(q_title, question_container):
    """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è·³éæ­¤é¡Œç›®ï¼ˆå›ºå®šæ¬„ä½ï¼‰"""
    # æª¢æŸ¥é¡Œç›®æ–‡å­—é—œéµå­—
    skip_keywords = ["å…¬å¸", "å‹é”", "é”æ“", "é”é‹", "æ¸¯å‹™å…¬å¸", "æœ¬äººå·²è©³é–±", "åŒæ„", "å€‹äººè³‡æ–™", "äº¤ç”±"]
    if any(keyword in q_title for keyword in skip_keywords):
        return True
    
    # æª¢æŸ¥é¸é …å…§å®¹
    try:
        options = []
        for option_div in await question_container.locator('[data-qa^="option-"]').all():
            option_text = (await option_div.text_content()).strip()
            if option_text:
                options.append(option_text)
        
        # æª¢æŸ¥å…¬å¸ç›¸é—œé¸é …
        company_keywords = ["å‹é”", "é”æ“", "é”é‹", "æ¸¯å‹™å…¬å¸", "å…¶ä»–"]
        company_count = sum(1 for option in options if any(keyword in option for keyword in company_keywords))
        if company_count >= 3:
            return True
        
        # æª¢æŸ¥åŒæ„æ›¸é¸é …
        if any("æœ¬äººå·²è©³é–±" in option or "åŒæ„" in option for option in options):
            return True
            
    except Exception:
        pass
    
    return False

class QuizCacheManager(CacheManager):
    """å•å·å°ˆç”¨çš„å¿«å–ç®¡ç†å™¨"""
    
    def load_survey_data(self, url):
        """è¼‰å…¥å•å·è³‡æ–™"""
        data = self.load_json_file("survey_data.json")
        url_hash = self.get_url_hash(url)
        return data.get(url_hash)
    
    def save_survey_data(self, url, all_qa, option_texts):
        """å„²å­˜å•å·è³‡æ–™"""
        data = self.load_json_file("survey_data.json")
        url_hash = self.get_url_hash(url)
        data[url_hash] = {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "all_qa": all_qa,
            "option_texts": option_texts
        }
        self.save_json_file("survey_data.json", data)
    
    def load_gpt_answers(self, url):
        """è¼‰å…¥ GPT ç­”æ¡ˆ"""
        data = self.load_json_file("gpt_answers.json")
        url_hash = self.get_url_hash(url)
        return data.get(url_hash)
    
    def save_gpt_answers(self, url, answers):
        """å„²å­˜ GPT ç­”æ¡ˆ"""
        data = self.load_json_file("gpt_answers.json")
        url_hash = self.get_url_hash(url)
        data[url_hash] = {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "answers": answers
        }
        self.save_json_file("gpt_answers.json", data)

# ========== å•å·è³‡æ–™æ“·å– ==========
async def extract_survey_data_with_cache(url, cache_manager):
    """å¸¶å¿«å–çš„å•å·è³‡æ–™æ“·å–"""
    cached_data = cache_manager.load_survey_data(url)
    if cached_data:
        app_logger.info("âœ… å¾å¿«å–è¼‰å…¥å•å·è³‡æ–™")
        return cached_data["all_qa"], cached_data["option_texts"]
    
    app_logger.info("ğŸ”„ å¿«å–ä¸­ç„¡è³‡æ–™ï¼Œé–‹å§‹çˆ¬å–å•å·...")
    
    all_qa = ""
    option_texts = {}
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto(url)
        await page.wait_for_timeout(2500)
        
        question_containers = await page.locator('[aria-label="subject answer container"]').all()
        actual_question_idx = 0
        
        for qc in question_containers:
            q_title = (await qc.locator('div[class^="css-"]').first.text_content()).strip()
            
            if await should_skip_question(q_title, qc):
                app_logger.info(f"è·³éé¡Œç›®: {q_title}")
                continue
                
            actual_question_idx += 1
            app_logger.info(f"è™•ç†é¡Œç›® {actual_question_idx}: {q_title}")
            
            # ç²å–é¸é …
            options = []
            option_divs = await qc.locator('[data-qa^="option-"]').all()
            for option_div in option_divs:
                option_text = (await option_div.text_content()).strip()
                if option_text:
                    options.append(option_text)
            
            if options:
                opt_letters = generate_option_letters(len(options))
                
                # ç‚º GPT æº–å‚™é¡Œç›®æ–‡å­—
                opt_lines = [f"{opt_letters[i]}. {opt}" for i, opt in enumerate(options)]
                opt_text = "\n".join(opt_lines)
                all_qa += f"{actual_question_idx}. {q_title}\n{opt_text}\n\n"
                
                # ç‚ºè‡ªå‹•å¡«å¯«æº–å‚™é¸é …å°æ‡‰è¡¨
                question_options = {opt_letters[i]: option_text for i, option_text in enumerate(options) if i < len(opt_letters)}
                option_texts[str(actual_question_idx)] = question_options
        
        await browser.close()
    
    cache_manager.save_survey_data(url, all_qa, option_texts)
    app_logger.info("ğŸ’¾ å•å·è³‡æ–™å·²å„²å­˜åˆ°å¿«å–")
    
    return all_qa, option_texts

# ========== GPT åˆ†æ ==========
def get_answer_by_gpt_with_cache(url, all_qa, cache_manager):
    """å¸¶å¿«å–çš„ GPT ç­”æ¡ˆç²å–"""
    cached_answers = cache_manager.load_gpt_answers(url)
    if cached_answers:
        app_logger.info("âœ… å¾å¿«å–è¼‰å…¥ GPT ç­”æ¡ˆ")
        return cached_answers["answers"]
    
    app_logger.info("ğŸ¤– å¿«å–ä¸­ç„¡ GPT ç­”æ¡ˆï¼Œé–‹å§‹åˆ†æ...")
    
    openai.api_key = OPENAI_API_KEY
    
    # ç¬¬ä¸€æ­¥ï¼šç²å–ç­”æ¡ˆ
    prompt = f"è«‹é‡å°ä»¥ä¸‹é¡Œç›®é¸å‡ºæ­£ç¢ºç­”æ¡ˆï¼Œåªè¦å›ç­”ã€é¡Œè™Ÿ: é¸é …å­—æ¯ã€å³å¯ï¼ˆä¸ç”¨è§£é‡‹ï¼‰ï¼š\n{all_qa}"
    resp = openai.ChatCompletion.create(
        model=openai_model,
        messages=[{"role": "user", "content": prompt}]
    )
    gpt_answer_text = resp['choices'][0]['message']['content']
    openai.ChatCompletion.update()
    # ç¬¬äºŒæ­¥ï¼šè½‰æ›ç‚º JSON
    prompt2 = f"å°‡ä¸‹åˆ—é¡Œè™Ÿèˆ‡ç­”æ¡ˆå­—æ¯æ•´ç†æˆ JSON æ ¼å¼ï¼ˆåªè¼¸å‡º JSONï¼Œkey ç‚ºé¡Œè™Ÿï¼Œvalue ç‚ºé¸é …å­—æ¯ï¼‰:\n{gpt_answer_text}"
    resp2 = openai.ChatCompletion.create(
        model=openai_model,
        messages=[{"role": "user", "content": prompt2}]
    )
    json_text = resp2['choices'][0]['message']['content']
    
    try:
        json_text = re.sub(r"^```json|```$", "", json_text, flags=re.MULTILINE).strip()
        answers = json.loads(json_text)
    except Exception:
        app_logger.error("JSON parse error:", json_text)
        raise
    
    cache_manager.save_gpt_answers(url, answers)
    app_logger.info("ğŸ’¾ GPT ç­”æ¡ˆå·²å„²å­˜åˆ°å¿«å–")
    
    return answers

# ========== å•å·å°ˆç”¨å¡«è¡¨å‡½æ•¸ ==========
async def fill_quiz_questions(page, name, answers, option_texts):
    """å¡«å¯«å•å·é¸æ“‡é¡Œ"""
    question_containers = await page.locator('[aria-label="subject answer container"]').all()
    actual_question_idx = 0
    
    for qc in question_containers:
        q_title = (await qc.locator('div[class^="css-"]').first.text_content()).strip()
        
        if await should_skip_question(q_title, qc):
            continue
            
        actual_question_idx += 1
        q_num = str(actual_question_idx)
        
        if q_num in answers and q_num in option_texts:
            option_letter = answers[q_num]
            if option_letter in option_texts[q_num]:
                option_content = option_texts[q_num][option_letter]
                selector = f'div[data-qa^="option-{option_content}"]'
                try:
                    await page.wait_for_selector(selector, timeout=3000)
                    await page.click(selector)
                    app_logger.info(f"å·²é¸æ“‡é¡Œç›® {q_num} çš„é¸é … {option_letter}: {option_content}")
                except Exception as e:
                    app_logger.error(f"ç„¡æ³•é»æ“Šé¡Œç›® {q_num} çš„é¸é … {option_letter}: {option_content}, éŒ¯èª¤: {e}")

# ========== ä¸»æµç¨‹å‡½å¼ (å¯è¢«å¤–éƒ¨å‘¼å«) ==========
async def run_quiz_automation(survey_url: str):
    """
    åŸ·è¡Œè‡ªå‹•æ¸¬é©—æµç¨‹çš„ä¸»å‡½å¼ã€‚

    Args:
        survey_url (str): è¦è™•ç†çš„æ¸¬é©—å•å·ç¶²å€ã€‚
    """
    app_logger.info(f"=== é–‹å§‹å•å·è‡ªå‹•åŒ–æµç¨‹ï¼ˆç›®æ¨™ URL: {survey_url}ï¼‰===")
    
    # åˆå§‹åŒ–å¿«å–ç®¡ç†å™¨
    cache_manager = QuizCacheManager()
    
    # æ­¥é©Ÿ 1: æ“·å–å•å·è³‡æ–™
    app_logger.info("\næ­¥é©Ÿ 1: æ“·å–å•å·è³‡æ–™ï¼ˆæª¢æŸ¥å¿«å–ï¼‰...")
    all_qa, option_texts = await extract_survey_data_with_cache(survey_url, cache_manager)
    
    app_logger.info("\n======= å•å·é¡Œç›®æŠ½å–çµæœ =======")
    app_logger.info(all_qa)
    
    # æ­¥é©Ÿ 2: GPT åˆ†æ
    app_logger.info("\næ­¥é©Ÿ 2: ä½¿ç”¨ GPT åˆ†æé¡Œç›®ï¼ˆæª¢æŸ¥å¿«å–ï¼‰...")
    answers = get_answer_by_gpt_with_cache(survey_url, all_qa, cache_manager)
    app_logger.info("======= GPT ç­”æ¡ˆï¼ˆJSONï¼‰=======")
    app_logger.info(json.dumps(answers, ensure_ascii=False, indent=2))
    
    # æ­¥é©Ÿ 3: å®šç¾©è‡ªå®šç¾©å¡«è¡¨å‡½æ•¸
    async def custom_quiz_fill(page, name):
        await fill_quiz_questions(page, name, answers, option_texts)
    
    # æ­¥é©Ÿ 4: æ‰¹æ¬¡è™•ç†
    app_logger.info("\næ­¥é©Ÿ 3: é–‹å§‹æ‰¹æ¬¡è™•ç†...")
    
    # å˜—è©¦ä½¿ç”¨æ–°çš„ç”¨æˆ¶ç®¡ç†ç³»çµ±
    try:
        # å‹•æ…‹å°å…¥ UserManagerï¼ˆé¿å…å¾ªç’°å°å…¥ï¼‰
        import sys
        import os
        
        # ç¢ºä¿å¯ä»¥å°å…¥ server æ¨¡çµ„
        sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
        
        try:
            from server import user_manager
            app_logger.info("ä½¿ç”¨ç”¨æˆ¶ç®¡ç†ç³»çµ±é€²è¡Œæ‰¹æ¬¡æ¸¬é©—è™•ç†...")
            await batch_process_forms_from_manager(
                url=survey_url,
                user_manager=user_manager,
                company_name=company_name,
                cache_manager=cache_manager,
                custom_fill_func=custom_quiz_fill
            )
        except ImportError:
            # å¦‚æœç„¡æ³•å°å…¥ç”¨æˆ¶ç®¡ç†å™¨ï¼Œå›é€€åˆ° CSV æ¨¡å¼
            app_logger.error("ç„¡æ³•ä½¿ç”¨ç”¨æˆ¶ç®¡ç†ç³»çµ±ï¼Œå›é€€åˆ° CSV æ¨¡å¼...")
            await batch_process_forms(
                url=survey_url,
                csv_path=CSV_PATH,
                company_name=company_name,
                cache_manager=cache_manager,
                custom_fill_func=custom_quiz_fill
            )
    except Exception as e:
        app_logger.error(f"æ¸¬é©—è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        # å›é€€åˆ° CSV æ¨¡å¼
        app_logger.error("å›é€€åˆ° CSV æ¨¡å¼...")
        await batch_process_forms(
            url=survey_url,
            csv_path=CSV_PATH,
            company_name=company_name,
            cache_manager=cache_manager,
            custom_fill_func=custom_quiz_fill
        )
    
    app_logger.info(f"\n=== å•å·è‡ªå‹•åŒ–å®Œæˆï¼å¿«å–æª”æ¡ˆä½ç½®: {cache_manager.cache_dir} ===")

# é€™å€‹å€å¡Šç¾åœ¨åªç”¨æ–¼ç¨ç«‹æ¸¬è©¦æ­¤æª”æ¡ˆ
if __name__ == "__main__":
    # ç”¨æ–¼ç¨ç«‹æ¸¬è©¦æ­¤æ¨¡çµ„çš„é è¨­ URL
    DEFAULT_QUIZ_URL = "https://www.surveycake.com/s/XGbl0"
    app_logger.info(">> æ­£åœ¨ä»¥ç¨ç«‹æ¨¡å¼åŸ·è¡Œ auto_quiz.py é€²è¡Œæ¸¬è©¦...")
    asyncio.run(run_quiz_automation(DEFAULT_QUIZ_URL))